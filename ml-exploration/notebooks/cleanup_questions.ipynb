{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to sys.path\n",
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove near-duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, Any\n",
    "\n",
    "def replace_escaped_quotes(input_string):\n",
    "    return input_string.replace('\\\\\"', \"'\")\n",
    "\n",
    "def deduplicate_with_fuzzy(entries, threshold):\n",
    "    # Using OrderedDict to preserve the order\n",
    "    deduped_entries = OrderedDict()\n",
    "\n",
    "    total_entries = len(entries)\n",
    "    duplicate_count = 0\n",
    "\n",
    "    for entry in entries:\n",
    "        question = entry[\"question\"]\n",
    "        duplicate_found = False\n",
    "        for existing_entry in deduped_entries.keys():\n",
    "            if fuzz.ratio(question, existing_entry) > threshold:\n",
    "                duplicate_found = True\n",
    "                duplicate_count += 1\n",
    "                print(f\"Duplicate entry found: '{question}' duplicates '{existing_entry}'\")\n",
    "                break\n",
    "        if not duplicate_found:\n",
    "            deduped_entries[question] = entry\n",
    "\n",
    "    unique_entries = len(deduped_entries)\n",
    "\n",
    "    print(f\"Total entries: {total_entries}\")\n",
    "    print(f\"Total duplicates: {duplicate_count}\")\n",
    "    print(f\"Total non-duplicates entries: {unique_entries}\")\n",
    "\n",
    "    return list(deduped_entries.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import OrderedDict\n",
    "\n",
    "def deduplicate_with_TfidfVectorizer(entries, threshold):\n",
    "    # Using OrderedDict to preserve the order\n",
    "    deduped_entries = OrderedDict()\n",
    "    duplicate_count = 0\n",
    "\n",
    "    lines = [entry['question'] for entry in entries]\n",
    "\n",
    "    # Calculate TF-IDF vectors for the lines\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(lines)\n",
    "\n",
    "    # Compute cosine similarity between the vectors\n",
    "    similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    for i, entry in enumerate(entries):\n",
    "        duplicate_found = False\n",
    "        for j in range(i + 1, len(entries)):\n",
    "            if similarities[i][j] > threshold:\n",
    "                print(f\"Duplicate entry found: '{entry['question']}' duplicates '{entries[j]['question']}'\")\n",
    "                duplicate_found = True\n",
    "                duplicate_count += 1\n",
    "                break\n",
    "\n",
    "        if not duplicate_found:\n",
    "            deduped_entries[entry['question']] = entry\n",
    "\n",
    "    non_duplicate_count = len(deduped_entries)\n",
    "    total_lines = len(entries)\n",
    "\n",
    "    print(f\"Total entries: {total_lines}\")\n",
    "    print(f\"Total duplicates: {duplicate_count}\")\n",
    "    print(f\"Total non-duplicates: {non_duplicate_count}\")\n",
    "\n",
    "    return list(deduped_entries.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 5096\n",
      "Total duplicates: 0\n",
      "Total unique entries: 5096\n",
      "Duplicate entry found: 'What do you hope to achieve during this new phase of your life?' duplicates 'What do you hope unicorn to achieve during this new phase of your life?'\n",
      "Total entries: 5096\n",
      "Total duplicates: 1\n",
      "Total non-duplicates: 5095\n",
      "Percentage of duplicates: 0.019623233908948195%\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "json_file = '../data/questions.json'  # specify your file path here\n",
    "fuzzy_threshold = 98  # specify your threshold here\n",
    "tfidf_threshold = 0.85\n",
    "\n",
    "save_to_file = True  # specify if you want to save the deduplicated lines back to the file\n",
    "\n",
    "with open(json_file, 'r') as f:\n",
    "        entries = json.load(f)\n",
    "\n",
    "for entry in entries:\n",
    "     entry['question'] = replace_escaped_quotes(entry['question'])\n",
    "\n",
    "deduped_lines = deduplicate_with_fuzzy(entries, fuzzy_threshold)\n",
    "deduped_lines = deduplicate_with_TfidfVectorizer(entries, tfidf_threshold)\n",
    "\n",
    "\n",
    "if save_to_file:\n",
    "    with open(json_file, 'w') as f:\n",
    "        # Use json.dump with indent parameter to format the output\n",
    "        json.dump(list(deduped_lines), f, indent=1, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Internal JSON dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def convert_json_to_csv(json_file, csv_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"question\", \"tags\"])\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Usage\n",
    "json_file = '../data/questions.json'  # specify the input JSON file path here\n",
    "csv_file = '../data/questions.csv'  # specify the output CSV file path here\n",
    "\n",
    "convert_json_to_csv(json_file, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
