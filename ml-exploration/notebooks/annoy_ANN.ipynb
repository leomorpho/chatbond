{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Annoy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from annoy import AnnoyIndex\n",
    "import ast\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data/questions.csv')\n",
    "\n",
    "# Convert the embedding strings to actual lists\n",
    "df['embedding_all_mpnet_base_v2'] = df['embedding_all_mpnet_base_v2'].apply(ast.literal_eval)\n",
    "\n",
    "# Initialize Annoy\n",
    "f = len(df.loc[0, 'embedding_all_mpnet_base_v2'])  # Length of item vector that will be indexed\n",
    "t = AnnoyIndex(f, 'angular')  # Use 'angular' for cosine distance\n",
    "\n",
    "# Add all the vectors to the index\n",
    "for i, row in df.iterrows():\n",
    "    t.add_item(i, row['embedding_all_mpnet_base_v2'])\n",
    "\n",
    "# Build the index\n",
    "t.build(10)  # 10 trees\n",
    "\n",
    "# Save the index\n",
    "t.save('questions.ann')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the index is built and saved, you can load it and use it to find similar questions based on their embeddings. Here's a function that does that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               question   \n",
      "0     What is something that you're afraid of that y...  \\\n",
      "2829                 What's something you're afraid of?   \n",
      "1661  What is one fear you have that you don't want ...   \n",
      "4970                     What brings you the most fear?   \n",
      "4456           What is a personal fear you've overcome?   \n",
      "3398        What is the biggest fear you have overcome?   \n",
      "1798  What is something you were afraid of as a chil...   \n",
      "4052  What is a dream you have that you’re afraid to...   \n",
      "1224  What's a fear about our relationship that keep...   \n",
      "2695  What is something you've always wanted to do b...   \n",
      "\n",
      "                                           tags   \n",
      "0            ['Fear Topic', 'Overcoming Topic']  \\\n",
      "2829         ['Fear Topic', 'Overcoming Topic']   \n",
      "1661         ['Fear Topic', 'Overcoming Topic']   \n",
      "4970         ['Fear Topic', 'Overcoming Topic']   \n",
      "4456         ['Fear Topic', 'Overcoming Topic']   \n",
      "3398         ['Fear Topic', 'Overcoming Topic']   \n",
      "1798         ['Fear Topic', 'Overcoming Topic']   \n",
      "4052                         ['Personal Goals']   \n",
      "1224  ['Relationship Feedback', 'Improvements']   \n",
      "2695                         ['Personal Goals']   \n",
      "\n",
      "                                     extracted_topics   \n",
      "0                     ['fear', 'fears', 'fears what']  \\\n",
      "2829                  ['fear', 'fears', 'fears what']   \n",
      "1661                  ['fear', 'fears', 'fears what']   \n",
      "4970                  ['fear', 'fears', 'fears what']   \n",
      "4456                  ['fear', 'fears', 'fears what']   \n",
      "3398                  ['fear', 'fears', 'fears what']   \n",
      "1798                  ['fear', 'fears', 'fears what']   \n",
      "4052                ['goal', 'to achieve', 'achieve']   \n",
      "1224  ['what fear', 'our relationship', 'fear about']   \n",
      "2695                ['goal', 'to achieve', 'achieve']   \n",
      "\n",
      "                               interpersonal_categories   \n",
      "0     ['self', 'friendship', 'romantic', 'family', '...  \\\n",
      "2829  ['self', 'friendship', 'romantic', 'family', '...   \n",
      "1661   ['self', 'friendship', 'family', 'professional']   \n",
      "4970                                           ['self']   \n",
      "4456  ['self', 'friendship', 'romantic', 'family', '...   \n",
      "3398                             ['self', 'friendship']   \n",
      "1798  ['self', 'friendship', 'family', 'professional...   \n",
      "4052                 ['self', 'friendship', 'romantic']   \n",
      "1224                                       ['romantic']   \n",
      "2695  ['self', 'friendship', 'romantic', 'family', '...   \n",
      "\n",
      "                            embedding_all_mpnet_base_v2  \n",
      "0     [0.041655391454696655, 0.006750224623829126, 0...  \n",
      "2829  [0.057802796363830566, -0.017262984067201614, ...  \n",
      "1661  [0.045990269631147385, 0.023786818608641624, -...  \n",
      "4970  [0.012562739662826061, -0.019361380487680435, ...  \n",
      "4456  [0.032107509672641754, 0.011170155368745327, -...  \n",
      "3398  [0.044938623905181885, -0.014777707867324352, ...  \n",
      "1798  [0.030690239742398262, -0.014504864811897278, ...  \n",
      "4052  [0.04619866982102394, 0.05213472247123718, -0....  \n",
      "1224  [0.05892690643668175, 0.013250757940113544, 0....  \n",
      "2695  [0.03342575952410698, 0.04290619120001793, -0....  \n"
     ]
    }
   ],
   "source": [
    "def find_similar_questions(question_id, index, df, n=10):\n",
    "    similar_ids = index.get_nns_by_item(question_id, n)\n",
    "    return df.loc[similar_ids]\n",
    "\n",
    "# Load the index\n",
    "u = AnnoyIndex(f, 'angular')\n",
    "u.load('questions.ann')  # super fast, will just mmap the file\n",
    "\n",
    "# Find similar questions to question id 0\n",
    "print(find_similar_questions(0, u, df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching and General Recommendations with Annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add718839e774064bc0100d078241a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ba213de6c446c8b3999265dd56d022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71c2d66b3df44ae800001c497f2b6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d7ad0c5b734bef889e492481c037b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af62e72852324984a5b66929e683cd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea106209e7c04749b6d6ca70e92a8cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8db0355ebc14cfaa7548488d84d4d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb3a3e09cd54674984d1db0f6c260fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b77ec10cb04f3590f8821089904526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49571d12d7948879c45c2ea1161078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969a5ca6004944d08b2797a618d4f377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5786ccdacb254d34bab2f846b68660fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe8972828f140c8810334c61a1971f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afadb8396d544131b70f5406862bcec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "csv_file = \"data/questions.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "questions = df[\"question\"].tolist()\n",
    "\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(questions, show_progress_bar=False)\n",
    "\n",
    "# Create an Annoy index\n",
    "f = embeddings.shape[1]  # Length of item vector that will be indexed\n",
    "t = AnnoyIndex(f, 'angular')\n",
    "\n",
    "# Add all the vectors to the index\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    t.add_item(i, embedding)\n",
    "\n",
    "# Build the index\n",
    "t.build(10)\n",
    "\n",
    "# Save the index\n",
    "t.save('sentences.ann')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you think of a moment when you felt proud of a family member?\n",
      "What is the most important thing you've learned from your family?\n",
      "What is the most important lesson you've learned in your life?\n",
      "When was the last time you were proud of yourself?\n",
      "What's one thing you're proud of yourself for this week?\n",
      "What's the most important thing you've learned from someone online?\n",
      "What is a personal goal you've recently achieved?\n",
      "What is your 'anima' or 'animus' - the inner feminine/masculine aspect of yourself?\n",
      "What is something you're proud of in your life?\n",
      "What's the most important life lesson you've learned so far?\n",
      "What's a moment when you felt very connected to me?\n",
      "What's one thing you wish I understood better about you?\n",
      "What is something you've done recently that you're proud of?\n",
      "What inspires you to keep going when things get tough?\n",
      "What is something you are proud of yourself for?\n",
      "What is a childhood accomplishment that you are proud of?\n",
      "What is something you appreciate more now that you are older?\n",
      "What is a life experience that has taught you an important lesson?\n",
      "What's one thing you're proud of in your life?\n",
      "What is something you have done that you are proud of, but don't often share with others?\n"
     ]
    }
   ],
   "source": [
    "# Now, when you want to find similar sentences to a search term:\n",
    "search_term = \"brother\"\n",
    "search_embedding = sentence_model.encode([search_term])\n",
    "\n",
    "# Find the ids of the 10 most similar sentences\n",
    "ids = t.get_nns_by_vector(search_embedding[0], 20)\n",
    "# Print the similar sentences\n",
    "for id in ids:\n",
    "    print(questions[id])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about finding good recommendations based on liked questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_to_centroid(embeddings, annoy_index, num_results=10):\n",
    "    # Calculate the centroid of the embeddings\n",
    "    centroid = np.mean(embeddings, axis=0)\n",
    "\n",
    "    # Query the Annoy index\n",
    "    nearest_ids = annoy_index.get_nns_by_vector(centroid, num_results)\n",
    "\n",
    "    return nearest_ids\n",
    "\n",
    "\n",
    "def create_embeddings(model, text_list):\n",
    "    embeddings = model.encode(text_list)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is something that you've done for someone else that made you feel good?\n",
      "What is the biggest lesson you've learned from a past relationship?\n",
      "What is the most important thing you've learned from your relationships?\n",
      "What is a lesson you've learned from your relationship?\n",
      "What do you believe is your greatest contribution to your relationships?\n",
      "What is something your partner does that makes you feel loved?\n",
      "What's one thing you appreciate about your partner?\n",
      "What's one thing about our relationship that you're most grateful for?\n",
      "What is the most important moral lesson you have learned from a past relationship?\n",
      "What is something you appreciate in a partner?\n"
     ]
    }
   ],
   "source": [
    "liked_questions = [\n",
    "    \"What is the biggest lesson you've learned in the past year?\",\n",
    "    \"What is something your partner does that makes you feel loved?\",\n",
    "    \"What is your idea of a supportive and loving partner?\",\n",
    "    \"What does forgiveness mean to you?\",\n",
    "    \"What is one mistake you've made that you've been able to laugh about?\",\n",
    "    \"What's a moment when you felt very connected to me?\",\n",
    "]\n",
    "embeddings = create_embeddings(sentence_model, liked_questions)\n",
    "\n",
    "ids = find_nearest_to_centroid(embeddings, t, 10)\n",
    "\n",
    "for id in ids:\n",
    "    print(questions[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
